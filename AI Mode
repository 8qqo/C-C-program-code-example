#include <stdio.h>
#include <stdlib.h>
#include <string.h>  // For strcmp

// 定義矩陣結構
typedef struct {
    int rows;
    int cols;
    double** data;
} Matrix;

// 初始化矩陣
Matrix* create_matrix(int rows, int cols) {
    Matrix* mat = (Matrix*)malloc(sizeof(Matrix));
    mat->rows = rows;
    mat->cols = cols;
    mat->data = (double**)malloc(rows * sizeof(double*));
    for (int i = 0; i < rows; i++) {
        mat->data[i] = (double*)malloc(cols * sizeof(double));
    }
    return mat;
}

// 前向傳播：計算預測值 y_pred = X * W + b
double forward(Matrix* X, Matrix* W, double* b) {
    double result = 0.0;
    for (int i = 0; i < X->rows; i++) {
        result += X->data[i][0] * W->data[i][0];
    }
    return result + *b;
}

// 均方誤差 (MSE) 損失函數
double mse(double y_true, double y_pred) {
    return (y_true - y_pred) * (y_true - y_pred);
}

// 更新權重和偏置：W -= learning_rate * gradient, b -= learning_rate * gradient
void update_weights(Matrix* W, double* b, double learning_rate, double gradient) {
    for (int i = 0; i < W->rows; i++) {
        W->data[i][0] -= learning_rate * gradient;
    }
    *b -= learning_rate * gradient;
}

// 訓練過程
void train(Matrix* X, double* y, Matrix* W, double* b, double learning_rate, int epochs) {
    for (int epoch = 0; epoch < epochs; epoch++) {
        double total_loss = 0.0;
        for (int i = 0; i < X->rows; i++) {
            double y_pred = forward(X, W, b);
            double loss = mse(y[i], y_pred);
            total_loss += loss;
            double gradient = 2 * (y_pred - y[i]);
            update_weights(W, b, learning_rate, gradient);
        }
        printf("Epoch %d: Loss = %f\n", epoch, total_loss / X->rows);
    }
}

// 主函數
int main() {
    // 初始化數據
    int rows = 2;
    Matrix* X = create_matrix(rows, 1);  // 輸入數據
    Matrix* W = create_matrix(rows, 1);  // 權重
    double b = 0.0;  // 偏置

    // 設定輸入數據
    X->data[0][0] = 1.0;
    X->data[1][0] = 2.0;

    // 初始化權重
    W->data[0][0] = 0.1;
    W->data[1][0] = 0.1;

    // 標籤數據
    double y[2] = {2.0, 3.0};

    // 訓練模型
    train(X, y, W, &b, 0.01, 1000);

    // 等待用戶輸入
    char input[10];
    printf("輸入 'clear' 清除結果並結束程序: ");
    fgets(input, 10, stdin);

    // 檢查用戶是否輸入 "clear"
    if (strcmp(input, "clear\n") == 0) {
        // 清除終端輸出
        system("clear");

        // 結束程序
        printf("已清除結果並結束程序。\n");
    }

    // 釋放內存
    for (int i = 0; i < rows; i++) {
        free(X->data[i]);
        free(W->data[i]);
    }
    free(X->data);
    free(W->data);
    free(X);
    free(W);

    return 0;
}



/*這段程式碼實現了一個簡單的機器學習訓練模型，並且提供了一個指令讓使用者可以在訓練結束後輸入 "clear" 來清除終端上的輸出並結束程式。現在我會詳細解釋各個部分的功能和流程。

1. 定義矩陣結構 (Matrix)

typedef struct {
    int rows;
    int cols;
    double** data;
} Matrix;

這段程式碼定義了一個矩陣 Matrix 的結構，它包含三個屬性：

	•	rows：矩陣的行數。
	•	cols：矩陣的列數。
	•	data：一個指向二維陣列的指標，用來儲存矩陣中的數據。

這個結構定義了矩陣的基礎形態，使得我們可以處理機器學習中的矩陣運算。

2. 初始化矩陣 (create_matrix)

Matrix* create_matrix(int rows, int cols) {
    Matrix* mat = (Matrix*)malloc(sizeof(Matrix));
    mat->rows = rows;
    mat->cols = cols;
    mat->data = (double**)malloc(rows * sizeof(double*));
    for (int i = 0; i < rows; i++) {
        mat->data[i] = (double*)malloc(cols * sizeof(double));
    }
    return mat;
}

這個函數用來初始化一個新的矩陣，它做了以下幾件事情：

	•	使用 malloc 為矩陣結構動態分配記憶體空間。
	•	為 data 動態分配一個二維陣列，這個陣列將存儲矩陣中的數據。
	•	函數返回一個指向已初始化矩陣的指標。

這樣，我們可以輕鬆地創建任意大小的矩陣，並在機器學習中用來表示數據集和權重等資料。

3. 前向傳播 (forward)

double forward(Matrix* X, Matrix* W, double* b) {
    double result = 0.0;
    for (int i = 0; i < X->rows; i++) {
        result += X->data[i][0] * W->data[i][0];
    }
    return result + *b;
}

這個函數實現了機器學習中的前向傳播，用來計算預測值 y_pred：

	•	X 是輸入矩陣，W 是權重矩陣，b 是偏置值。
	•	它將輸入數據 X 和權重 W 逐項相乘，然後加上偏置 b，得到模型的預測結果 y_pred。

這個過程模擬了機器學習中的線性模型計算，即：y_pred = X * W + b。

4. 均方誤差 (MSE) 損失函數

double mse(double y_true, double y_pred) {
    return (y_true - y_pred) * (y_true - y_pred);
}

這個函數計算模型的損失，使用的是均方誤差 (MSE)：

	•	y_true 是真實值，y_pred 是模型的預測值。
	•	損失函數衡量預測結果與真實值之間的差距，MSE 公式是兩者差的平方。

這個損失值越小，表示模型預測得越準確。

5. 更新權重和偏置 (update_weights)

void update_weights(Matrix* W, double* b, double learning_rate, double gradient) {
    for (int i = 0; i < W->rows; i++) {
        W->data[i][0] -= learning_rate * gradient;
    }
    *b -= learning_rate * gradient;
}

這個函數根據計算出的梯度來更新權重 W 和偏置 b：

	•	梯度是損失函數對參數的偏導數，指示了參數需要如何調整以降低損失。
	•	每個權重和偏置都根據梯度和學習率 (learning_rate) 來更新，學習率控制了更新的步伐大小。

這一步模擬了機器學習中的反向傳播，使得模型逐步學習以優化參數。

6. 訓練過程 (train)

void train(Matrix* X, double* y, Matrix* W, double* b, double learning_rate, int epochs) {
    for (int epoch = 0; epoch < epochs; epoch++) {
        double total_loss = 0.0;
        for (int i = 0; i < X->rows; i++) {
            double y_pred = forward(X, W, b);
            double loss = mse(y[i], y_pred);
            total_loss += loss;
            double gradient = 2 * (y_pred - y[i]);
            update_weights(W, b, learning_rate, gradient);
        }
        printf("Epoch %d: Loss = %f\n", epoch, total_loss / X->rows);
    }
}

這個訓練函數反覆進行 epochs 次模型更新過程：

	•	在每次訓練迭代中，通過前向傳播計算預測值 y_pred，再計算損失 loss，然後根據損失計算梯度。
	•	使用梯度來更新權重和偏置，使得模型在每次迭代中更加接近正確的結果。
	•	訓練過程中，會輸出每個 epoch 的平均損失，幫助我們了解模型的學習進度。

7. 等待用戶輸入並清除輸出 (clear)

char input[10];
printf("輸入 'clear' 清除結果並結束程序: ");
fgets(input, 10, stdin);

if (strcmp(input, "clear\n") == 0) {
    system("clear");
    printf("已清除結果並結束程序。\n");
}

這段程式碼實現了在訓練結束後等待使用者輸入指令：

	•	fgets 讀取使用者輸入，並將其存入 input 陣列。
	•	strcmp 用來比較使用者的輸入是否為 "clear"。
	•	如果使用者輸入 "clear"，程式會使用 system("clear") 清除終端上的輸出，並印出結束訊息。

這裡的 system("clear") 只適用於 Unix-like 系統。如果是在 Windows 系統上運行，則需要將其改為 system("cls")。

8. 記憶體釋放

for (int i = 0; i < rows; i++) {
    free(X->data[i]);
    free(W->data[i]);
}
free(X->data);
free(W->data);
free(X);
free(W);

這部分負責釋放程式中動態分配的記憶體，防止記憶體洩漏。對於每個用 malloc 分配的陣列和結構，必須在程式結束前用 free 釋放。*/